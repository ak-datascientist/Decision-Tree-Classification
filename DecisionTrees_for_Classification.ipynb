{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHldSpXQbnvt"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zThaAne6bnvv"
      },
      "outputs": [],
      "source": [
        "# Training dataset\n",
        "# x1 atmospheric pressure\n",
        "x1 = ['high', 'high', 'low', 'low', 'low', 'high']\n",
        "# x2 is weather type\n",
        "x2 = ['partly cloudy', 'sunny', 'sunny', 'cloudy', 'cloudy', 'cloudy']\n",
        "X = np.array([x1, x2]).T\n",
        "y = np.array([False, False, True, False, False, True]) # rain (True) and no-rain (False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ill7Ifgbnvw",
        "outputId": "f8453d30-418a-4910-f670-d33fdbfbef9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['high', 'partly cloudy'],\n",
              "       ['high', 'sunny'],\n",
              "       ['low', 'sunny'],\n",
              "       ['low', 'cloudy'],\n",
              "       ['low', 'cloudy'],\n",
              "       ['high', 'cloudy']], dtype='<U13')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X # features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Hc960f0bnvx",
        "outputId": "74ba9c59-8353-467b-e2ec-1f6748b4d646",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False,  True, False, False,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "y # labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqKKG-Ldbnvy",
        "outputId": "da8c207e-c51d-4f96-9d2f-bb595ca6244d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_1 = cloudy:\n",
            " x_0 = high: True\n",
            " x_0 = low: False\n",
            "x_1 = partly cloudy: False\n",
            "x_1 = sunny:\n",
            " x_0 = high: False\n",
            " x_0 = low: True\n"
          ]
        }
      ],
      "source": [
        "# Splitting a set\n",
        "# Input is an array of feature observations and output is a dictionary with \"unique feature value\" as key and indices as value\n",
        "def partition(a):\n",
        "    return {c: (a==c).nonzero()[0] for c in np.unique(a)}\n",
        "\n",
        "# Picking which attribute to split\n",
        "# Calculate entropy of a list\n",
        "def entropy(s):\n",
        "    res = 0\n",
        "    val, counts = np.unique(s, return_counts=True)\n",
        "    freqs = counts.astype('float')/len(s)\n",
        "    for p in freqs:\n",
        "        if p != 0.0:\n",
        "            res -= p * np.log2(p)\n",
        "    return res\n",
        "\n",
        "# Calculate decrease in impurity (information gains)\n",
        "#\n",
        "def mutual_information(y, x):\n",
        "\n",
        "    # Calculate entropy of observation classes\n",
        "    res = entropy(y)\n",
        "\n",
        "    # We partition x, according to attribute values x_i\n",
        "    val, counts = np.unique(x, return_counts=True)\n",
        "    freqs = counts.astype('float')/len(x)\n",
        "\n",
        "    # We calculate a weighted average of the entropy and subtract it from parent entropy\n",
        "    for p, v in zip(freqs, val):\n",
        "        res -= p * entropy(y[x == v])\n",
        "\n",
        "    return res\n",
        "\n",
        "# Checks for pureness of elements in a list\n",
        "def is_pure(s):\n",
        "    return len(set(s)) == 1\n",
        "\n",
        "# Helper function to print decision tree\n",
        "def print_tree(d, depth = 0):\n",
        "    for key, value in d.items():\n",
        "        for i in range(depth):\n",
        "                print(' ', end='')\n",
        "        if type(value) is dict:\n",
        "            print(key, end=':\\n')\n",
        "            print_tree(value, depth + 1)\n",
        "        else:\n",
        "            print(key, end=': ')\n",
        "            print(value)\n",
        "\n",
        "# Get the most common element of an array\n",
        "def most_common(a):\n",
        "    (values,counts) = np.unique(a,return_counts=True)\n",
        "    ind=np.argmax(counts)\n",
        "    return values[ind]\n",
        "\n",
        "# Recursive split of observations\n",
        "def recursive_split(x, y):\n",
        "\n",
        "    # If set to be split is pure or empty, return it as leaf\n",
        "    if is_pure(y) or len(y) == 0:\n",
        "        return most_common(y)\n",
        "\n",
        "    # Calculate decrease in impurity (information gain) and split attribute with maximum gain\n",
        "    gain = np.array([mutual_information(y, x_attr) for x_attr in x.T])\n",
        "    selected_attr = np.argmax(gain)\n",
        "\n",
        "    # Sufficiently pure, return it as leaf\n",
        "    if np.all(gain < 1e-6):\n",
        "        return most_common(y)\n",
        "\n",
        "    # Split using the selected attribute\n",
        "    sets = partition(x[:, selected_attr])\n",
        "\n",
        "    # Perform recursive splits and collect results\n",
        "    res = {}\n",
        "    for key, value in sets.items():\n",
        "        y_subset = y.take(value, axis=0)\n",
        "        x_subset = x.take(value, axis=0)\n",
        "        res[\"x_%d = %s\" % (selected_attr, key)] = recursive_split(x_subset, y_subset)\n",
        "\n",
        "    return res\n",
        "\n",
        "# Perform algorithm on the example dataset to create a decision tree\n",
        "d = recursive_split(X, y)\n",
        "print_tree(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7dMFZeMbnv0"
      },
      "outputs": [],
      "source": [
        "# New dataset (which shall be classified by the above generated decision tree)\n",
        "x1 = ['high', 'low', 'low', 'high', 'low', 'high', 'high', 'low', 'low', 'high', 'low', 'low']\n",
        "x2 = ['sunny', 'sunny', 'cloudy', 'cloudy', 'partly cloudy', 'cloudy', 'partly cloudy', 'cloudy', 'sunny', 'cloudy', 'cloudy', 'partly cloudy']\n",
        "X = np.array([x1, x2]).T\n",
        "y = np.array([False, True, True, False, False, True, False, True, True, False, True, True]) # ground-truth of classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01q_L3a_bnv1"
      },
      "source": [
        "# 1.2 Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zqyimyLbnv2"
      },
      "outputs": [],
      "source": [
        "#Recursive labelling of the samples\n",
        "def predict_rains(d,sample):\n",
        "    for key, value in d.items():\n",
        "        nodeKey,condValue = key.replace(\" \",\"\").split(\"=\")\n",
        "        selected_attr = 0\n",
        "\n",
        "        if(\"1\" in nodeKey):\n",
        "            selected_attr= 1\n",
        "\n",
        "        #Choose atmospheric pressure (0) or weather type(1) based on the condition at the node\n",
        "        sampleValue = sample[selected_attr]\n",
        "\n",
        "        if type(value) is dict:\n",
        "            if( sampleValue.replace(\" \",\"\") == condValue.replace(\" \",\"\")):\n",
        "                predict_rains(value,sample)\n",
        "        else:\n",
        "            if(sampleValue.replace(\" \",\"\") == condValue.replace(\" \",\"\")):\n",
        "                predictedValuesList.append(value)\n",
        "                #print(\" Label --> \",value)\n",
        "                if(value):\n",
        "                  print('\\nPrediction: Rains')\n",
        "                else:\n",
        "                  print('\\nPrediction: No Rains')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwxmIonUbnv3",
        "outputId": "fa98ecdb-eb87-4b14-cc8b-4e0514d8768a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['high' 'sunny']:\n",
            "Prediction: No Rains\n",
            "['low' 'sunny']:\n",
            "Prediction: Rains\n",
            "['low' 'cloudy']:\n",
            "Prediction: No Rains\n",
            "['high' 'cloudy']:\n",
            "Prediction: Rains\n",
            "['low' 'partly cloudy']:\n",
            "Prediction: No Rains\n",
            "['high' 'cloudy']:\n",
            "Prediction: Rains\n",
            "['high' 'partly cloudy']:\n",
            "Prediction: No Rains\n",
            "['low' 'cloudy']:\n",
            "Prediction: No Rains\n",
            "['low' 'sunny']:\n",
            "Prediction: Rains\n",
            "['high' 'cloudy']:\n",
            "Prediction: Rains\n",
            "['low' 'cloudy']:\n",
            "Prediction: No Rains\n",
            "['low' 'partly cloudy']:\n",
            "Prediction: No Rains\n"
          ]
        }
      ],
      "source": [
        "predictedValuesList=[]\n",
        "for sample in X:\n",
        "    print(sample,end=':')\n",
        "    predict_rains(d,sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uTzzlZ2bnv4"
      },
      "source": [
        "# 1.3 Overall Error Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWUQdJjfbnv4"
      },
      "outputs": [],
      "source": [
        "groundTruthOfClassification=y.tolist()\n",
        "data=np.array([x1, x2, predictedValuesList, groundTruthOfClassification]).T\n",
        "errorCount=0\n",
        "#Comparing the predicted and ground truth value to check the error\n",
        "for index in range(0,len(groundTruthOfClassification)):\n",
        "    if(groundTruthOfClassification[index]!=predictedValuesList[index]):\n",
        "        errorCount+=1\n",
        "# w.kt. Error Rate=Error Count(false values)/Total number of samples\n",
        "print(\"Overall Error Rate of the new dataset ( % ) : \",(errorCount/len(data))*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtPB9hR4bnv5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}